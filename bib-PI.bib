% Encoding: UTF-8

@Article{Bruhn2016,
  author    = {Miriam Bruhn and Luciana de Souza Le{\~{a}}o and Arianna Legovini and Rogelio Marchetti and Bilal Zia},
  journal   = {American Economic Journal: Applied Economics},
  title     = {The Impact of High School Financial Education: Evidence from a Large-Scale Evaluation in Brazil},
  year      = {2016},
  month     = {oct},
  number    = {4},
  pages     = {256--295},
  volume    = {8},
  doi       = {10.1257/app.20150149},
  publisher = {American Economic Association},
}

@Article{Chaisemartin2019,
  author        = {Clément de Chaisemartin and Jaime Ramirez-Cuellar},
  title         = {At What Level Should One Cluster Standard Errors in Paired and Small-Strata Experiments?},
  year          = {2019},
  month         = jun,
  abstract      = {In paired experiments, units are matched into pairs, and one unit of each pair is randomly assigned to treatment. To estimate the treatment effect, researchers often regress their outcome on a treatment indicator and pair fixed effects, clustering standard errors at the unit-of-randomization level. We show that the variance estimator in this regression may be severely downward biased: under constant treatment effect, its expectation equals 1/2 of the true variance. Instead, we show that researchers should cluster their standard errors at the pair level. Using simulations, we show that those results extend to stratified experiments with few units per strata.},
  archiveprefix = {arXiv},
  eprint        = {1906.00288},
  file          = {:http\://arxiv.org/pdf/1906.00288v7:PDF},
  keywords      = {econ.EM},
  primaryclass  = {econ.EM},
}

@InCollection{Duflo2007,
  author    = {Esther Duflo and Rachel Glennerster and Michael Kremer},
  booktitle = {Handbook of Development Economics},
  publisher = {Elsevier},
  title     = {Chapter 61 Using Randomization in Development Economics Research: A Toolkit},
  year      = {2007},
  pages     = {3895--3962},
  doi       = {10.1016/s1573-4471(07)04061-2},
}

@Article{Ferman2021,
  author        = {Ferman, Bruno},
  journal       = {{arXiv}:1912.08772 [econ]},
  title         = {Assessing Inference Methods},
  year          = {2021},
  month         = oct,
  note          = {version: 12},
  abstract      = {We analyze different assessments based on simulations that applied researchers may use to evaluate the reliability of their inference methods. We show that different types of simulations vary in many dimensions and present subtle issues when considered as inference assessments. We present evidence that even the use of simple and easy-to-implement assessments can detect problems in many different settings. While more complex assessments may detect problems that simpler assessments would not detect, they do not uniformly dominate simpler assessments in this dimension. Moreover, considering more complex assessments may induce some costs, ranging from necessity of application-specific modifications to sequential-testing distortions.},
  archiveprefix = {arxiv},
  eprint        = {1912.08772},
  file          = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1912.08772v12.pdf:application/pdf},
  keywords      = {Economics - Econometrics},
}

@Book{Imbens2015,
  author    = {Guido W. Imbens and Donald B. Rubin},
  publisher = {Cambridge University Press},
  title     = {Causal Inference for Statistics, Social, and Biomedical Sciences},
  year      = {2015},
  month     = {apr},
  doi       = {10.1017/cbo9781139025751},
}

@Article{Zhao2021,
  author       = {Zhao, Anqi and Ding, Peng},
  journal      = {Journal of Econometrics},
  title        = {Covariate-adjusted Fisher randomization tests for the average treatment effect},
  year         = {2021},
  issn         = {0304-4076},
  month        = dec,
  number       = {2},
  pages        = {278--294},
  volume       = {225},
  abstract     = {Fisher’s randomization test (frt) delivers exact p-values under the strong null hypothesis of no treatment effect on any units whatsoever and allows for flexible covariate adjustment to improve the power. Of interest is whether the resulting covariate-adjusted procedure could also be valid for testing the weak null hypothesis of zero average treatment effect. To this end, we evaluate two general strategies for conducting covariate adjustment in frts: the pseudo-outcome strategy that uses the residuals from an outcome model with only the covariates as the pseudo, covariate-adjusted outcomes to form the test statistic, and the model-output strategy that directly uses the output from an outcome model with both the treatment and covariates as the covariate-adjusted test statistic. Based on theory and simulation, we recommend using the ordinary least squares (ols) fit of the observed outcome on the treatment, centered covariates, and their interactions for covariate adjustment, and conducting frt with the robust t-value of the treatment as the test statistic. The resulting frt is finite-sample exact for testing the strong null hypothesis, asymptotically valid for testing the weak null hypothesis, and more powerful than the unadjusted counterpart under alternatives, all irrespective of whether the linear model is correctly specified or not. We start with complete randomization, and then extend the theory to cluster randomization, stratified randomization, and rerandomization, respectively, giving a recommendation for the test procedure and test statistic under each design. Our theory is design-based, also known as randomization-based, in which we condition on the potential outcomes but average over the random treatment assignment.},
  doi          = {10.1016/j.jeconom.2021.04.007},
  file         = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/abs/pii/S0304407621001457/pdfft?isDTMRedir=true&download=true:application/pdf},
  keywords     = {Finite-population inference, Permutation test, Randomization distribution, Robust standard error, Studentization, Super-population inference},
  langid       = {english},
  series       = {Themed Issue: Treatment Effect 1},
  shortjournal = {Journal of Econometrics},
}

@Unpublished{Hansen21,
  author = {Bruce Hansen},
  note   = {Graduate Textbook (draft)},
  title  = {Econometrics},
  month  = {3},
  year   = {2021},
  url    = {https://ssc.wisc.edu/~bhansen/econometrics/},
}

@Misc{Fischer21,
  author = {Alexander Fischer and David Roodman},
  title  = {fwildclusterboot: Fast Wild Cluster Bootstrap Inference for Linear Regression Models (Version 0.5.1)},
  year   = {2021},
  url    = {https://cran.r-project.org/package=fwildclusterboot},
}

@Article{Roodman2019,
  author       = {Roodman, David and Nielsen, Morten Ørregaard and {MacKinnon}, James G. and Webb, Matthew D.},
  journal      = {The Stata Journal},
  title        = {Fast and wild: Bootstrap inference in Stata using boottest},
  year         = {2019},
  issn         = {1536-867X},
  month        = mar,
  number       = {1},
  pages        = {4--60},
  volume       = {19},
  abstract     = {The wild bootstrap was originally developed for regression models with heteroskedasticity of unknown form. Over the past 30 years, it has been extended to models estimated by instrumental variables and maximum likelihood and to ones where the error terms are (perhaps multiway) clustered. Like bootstrap methods in general, the wild bootstrap is especially useful when conventional inference methods are unreliable because large-sample assumptions do not hold. For example, there may be few clusters, few treated clusters, or weak instruments. The package boottest can perform a wide variety of wild bootstrap tests, often at remarkable speed. It can also invert these tests to construct confidence sets. As a postestimation command, boottest works after linear estimation commands, including regress, cnsreg, ivregress, ivreg2, areg, and reghdfe, as well as many estimation commands based on maximum likelihood. Although it is designed to perform the wild cluster bootstrap, boottest can also perform the ordinary (nonclustered) version. Wrappers offer classical Wald, score/Lagrange multiplier, and Anderson–Rubin tests, optionally with (multiway) clustering. We review the main ideas of the wild cluster bootstrap, offer tips for use, explain why it is particularly amenable to computational optimization, state the syntax of boottest, artest, scoretest, and waldtest, and present several empirical examples.},
  doi          = {10.1177/1536867X19830877},
  file         = {SAGE PDF Full Text:https\://journals.sagepub.com/doi/pdf/10.1177/1536867X19830877:application/pdf},
  keywords     = {st0549, boottest, artest, waldtest, scoretest, Anderson–Rubin test, Wald test, wild bootstrap, wild cluster bootstrap, score bootstrap, multiway clustering, few treated clusters},
  langid       = {english},
  publisher    = {{SAGE} Publications},
  shortjournal = {The Stata Journal},
  shorttitle   = {Fast and wild},
}

@Article{Canay2021,
  author       = {Canay, Ivan A. and Santos, Andres and Shaikh, Azeem M.},
  journal      = {The Review of Economics and Statistics},
  title        = {The Wild Bootstrap with a “Small” Number of “Large” Clusters},
  year         = {2021},
  issn         = {0034-6535},
  month        = may,
  number       = {2},
  pages        = {346--363},
  volume       = {103},
  abstract     = {This paper studies the wild bootstrap–based test proposed in Cameron, Gelbach, and Miller (2008). Existing analyses of its properties require that number of clusters is “large.” In an asymptotic framework in which the number of clusters is “small,” we provide conditions under which an unstudentized version of the test is valid. These conditions include homogeneity-like restrictions on the distribution of covariates. We further establish that a studentized version of the test may only overreject the null hypothesis by a “small” amount that decreases exponentially with the number of clusters. We obtain a qualitatively similar result for “score” bootstrap-based tests, which permit testing in nonlinear models.},
  doi          = {10.1162/rest_a_00887},
  shortjournal = {The Review of Economics and Statistics},
}

@Comment{jabref-meta: databaseType:bibtex;}
